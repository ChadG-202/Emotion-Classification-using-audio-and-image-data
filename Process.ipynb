{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "temporal-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dutch-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATASET_AUDIO_TRAIN = \"EmotionDataset/Train/Audio\"\n",
    "DATASET_IMAGE_TRAIN = \"EmotionDataset/Train/Image\"\n",
    "JSON_TRAIN = \"json_storage/data.json\"\n",
    "\n",
    "DATASET_AUDIO_TRAIN = \"EmotionDataset/Test/Audio\"\n",
    "DATASET_IMAGE_TRAIN = \"EmotionDataset/Test/Image\"\n",
    "JSON_TRAIN = \"json_storage/test.json\"\n",
    "\n",
    "# Audio Var\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 2\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Image Var\n",
    "IMG_SIZE = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "optional-database",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Audio\\Happy\n",
      "EmotionDataset/Test/Audio\\Happy\\fate.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\gap.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\great.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\half.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\happy.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\hug.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\jail.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\keep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\kick.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\lamp.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\lean.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\make.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\mend.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\neutral.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\pain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\pen.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\rain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\sad.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\sheep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\thought.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\tree.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\voice.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\white.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\young.wav, segment:1\n",
      "\n",
      "Processing Audio\\Neutral\n",
      "EmotionDataset/Test/Audio\\Neutral\\fate.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\gap.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\great.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\half.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\happy.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\hug.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\jail.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\keep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\kick.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\lamp.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\lean.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\make.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\mend.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\neutral.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\pain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\pen.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\rain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\sad.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\sheep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\thought.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\tree.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\voice.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\white.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\young.wav, segment:1\n",
      "\n",
      "Processing Audio\\Sad\n",
      "EmotionDataset/Test/Audio\\Sad\\fate.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\gap.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\great.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\half.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\happy.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\hug.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\jail.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\keep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\kick.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\lamp.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\lean.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\make.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\mend.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\neutral.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\pain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\pen.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\rain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\sad.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\sheep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\thought.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\tree.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\voice.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\white.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\young.wav, segment:1\n",
      "\n",
      "Processing Image\\Happy\n",
      "EmotionDataset/Test/Image\\Happy\\1.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\10.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\11.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\12.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\13.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\14.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\15.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\16.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\17.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\18.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\19.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\2.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\20.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\21.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\22.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\23.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\24.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\3.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\4.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\5.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\6.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\7.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\8.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\9.jpg\n",
      "\n",
      "Processing Image\\Neutral\n",
      "EmotionDataset/Test/Image\\Neutral\\1.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\10.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\11.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\12.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\13.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\14.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\15.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\16.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\17.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\18.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\19.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\2.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\20.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\21.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\22.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\23.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\24.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\3.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\4.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\5.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\6.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\7.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\8.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\9.jpg\n",
      "\n",
      "Processing Image\\Sad\n",
      "EmotionDataset/Test/Image\\Sad\\1.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\10.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\11.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\12.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\13.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\14.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\15.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\16.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\17.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\18.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\19.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\2.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\20.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\21.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\22.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\23.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\24.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\3.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\4.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\5.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\6.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\7.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\8.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\9.jpg\n"
     ]
    }
   ],
   "source": [
    "# Process audio and image data - store in data.json file\n",
    "def save_data(audio_path, image_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=1):\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"mfcc\": [],\n",
    "        \"image\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "    \n",
    "    # how many samples for each audio input\n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments) \n",
    "    # number of mfccs if samples are made\n",
    "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length) \n",
    "    \n",
    "    # walk through audio directories\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(audio_path)):\n",
    "        if dirpath is not audio_path:\n",
    "            dirpath_components = dirpath.split(\"/\")\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            # store the directories opened\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            \n",
    "            print(\"\\nProcessing {}\".format(semantic_label))\n",
    "            \n",
    "            for f in filenames:\n",
    "                try:\n",
    "                    file_path = os.path.join(dirpath, f)\n",
    "                    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                except Exception as e:                                                    \n",
    "                    print('Audio failed to process: ' + e)\n",
    "                \n",
    "                for s in range(num_segments):\n",
    "                    # Process audio\n",
    "                    start_sample = num_samples_per_segment * s\n",
    "                    finish_sample = start_sample + num_samples_per_segment\n",
    "                        \n",
    "                    mfcc = librosa.feature.mfcc(signal[start_sample:finish_sample],\n",
    "                                               sr=sr,\n",
    "                                               n_fft=n_fft,\n",
    "                                               n_mfcc=n_mfcc,\n",
    "                                               hop_length=hop_length)\n",
    "\n",
    "                    mfcc = mfcc.T\n",
    "                    \n",
    "                    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                        # store mfcc data\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        # store audio type\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(\"{}, segment:{}\".format(file_path, s+1))\n",
    "    \n",
    "    # walk through image directories\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(image_path)):\n",
    "        if dirpath is not image_path:\n",
    "            dirpath_components = dirpath.split(\"/\")\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            # store the directories opened\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            \n",
    "            print(\"\\nProcessing {}\".format(semantic_label))\n",
    "            \n",
    "            for f in filenames:\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                try:\n",
    "                    # process image\n",
    "                    img_array = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) \n",
    "                    sized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                    # store image data\n",
    "                    data[\"image\"].append(sized_array.tolist())\n",
    "                    print(\"{}\".format(file_path))\n",
    "                except Exception as e:                                                    \n",
    "                    print('Image failed to process: ' + e)\n",
    "    \n",
    "    # dump stored data into json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "        \n",
    "\n",
    "save_data(DATASET_AUDIO_TRAIN, DATASET_IMAGE_TRAIN, JSON_TRAIN, num_segments=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "corresponding-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Audio\\Happy\n",
      "EmotionDataset/Test/Audio\\Happy\\fate.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\gap.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\great.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\half.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\happy.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\hug.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\jail.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\keep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\kick.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\lamp.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\lean.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\make.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\mend.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\neutral.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\pain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\pen.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\rain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\sad.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\sheep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\thought.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\tree.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\voice.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\white.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Happy\\young.wav, segment:1\n",
      "\n",
      "Processing Audio\\Neutral\n",
      "EmotionDataset/Test/Audio\\Neutral\\fate.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\gap.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\great.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\half.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\happy.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\hug.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\jail.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\keep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\kick.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\lamp.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\lean.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\make.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\mend.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\neutral.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\pain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\pen.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\rain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\sad.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\sheep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\thought.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\tree.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\voice.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\white.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Neutral\\young.wav, segment:1\n",
      "\n",
      "Processing Audio\\Sad\n",
      "EmotionDataset/Test/Audio\\Sad\\fate.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\gap.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\great.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\half.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\happy.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\hug.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\jail.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\keep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\kick.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\lamp.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\lean.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\make.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\mend.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\neutral.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\pain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\pen.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\rain.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\sad.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\sheep.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\thought.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\tree.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\voice.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\white.wav, segment:1\n",
      "EmotionDataset/Test/Audio\\Sad\\young.wav, segment:1\n",
      "\n",
      "Processing Image\\Happy\n",
      "EmotionDataset/Test/Image\\Happy\\1.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\10.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\11.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\12.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\13.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\14.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\15.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\16.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\17.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\18.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\19.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\2.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\20.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\21.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\22.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\23.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\24.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\3.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\4.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\5.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\6.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\7.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\8.jpg\n",
      "EmotionDataset/Test/Image\\Happy\\9.jpg\n",
      "\n",
      "Processing Image\\Neutral\n",
      "EmotionDataset/Test/Image\\Neutral\\1.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\10.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\11.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\12.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\13.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\14.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\15.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\16.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\17.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\18.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\19.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\2.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\20.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\21.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\22.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\23.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\24.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\3.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\4.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\5.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\6.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\7.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\8.jpg\n",
      "EmotionDataset/Test/Image\\Neutral\\9.jpg\n",
      "\n",
      "Processing Image\\Sad\n",
      "EmotionDataset/Test/Image\\Sad\\1.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\10.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\11.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\12.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\13.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\14.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\15.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\16.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\17.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\18.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\19.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\2.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\20.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\21.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\22.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\23.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\24.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\3.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\4.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\5.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\6.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\7.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\8.jpg\n",
      "EmotionDataset/Test/Image\\Sad\\9.jpg\n"
     ]
    }
   ],
   "source": [
    "def save_test_data(audio_path, image_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=1):\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"mfcc\": [],\n",
    "        \"image\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "    \n",
    "    # how many samples for each audio input\n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments) \n",
    "    # number of mfccs if samples are made\n",
    "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length) \n",
    "    \n",
    "    # walk through audio directories\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(audio_path)):\n",
    "        if dirpath is not audio_path:\n",
    "            dirpath_components = dirpath.split(\"/\")\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            # store the directories opened\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            \n",
    "            print(\"\\nProcessing {}\".format(semantic_label))\n",
    "            \n",
    "            for f in filenames:\n",
    "                try:\n",
    "                    file_path = os.path.join(dirpath, f)\n",
    "                    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                except Exception as e:                                                    \n",
    "                    print('Audio failed to process: ' + e)\n",
    "                \n",
    "                for s in range(num_segments):\n",
    "                    # Process audio\n",
    "                    start_sample = num_samples_per_segment * s\n",
    "                    finish_sample = start_sample + num_samples_per_segment\n",
    "                        \n",
    "                    mfcc = librosa.feature.mfcc(signal[start_sample:finish_sample],\n",
    "                                               sr=sr,\n",
    "                                               n_fft=n_fft,\n",
    "                                               n_mfcc=n_mfcc,\n",
    "                                               hop_length=hop_length)\n",
    "\n",
    "                    mfcc = mfcc.T\n",
    "                    \n",
    "                    if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                        # store mfcc data\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        # store audio type\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(\"{}, segment:{}\".format(file_path, s+1))\n",
    "    \n",
    "    # walk through image directories\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(image_path)):\n",
    "        if dirpath is not image_path:\n",
    "            dirpath_components = dirpath.split(\"/\")\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            # store the directories opened\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            \n",
    "            print(\"\\nProcessing {}\".format(semantic_label))\n",
    "            \n",
    "            for f in filenames:\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                try:\n",
    "                    # process image\n",
    "                    img_array = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE) \n",
    "                    sized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                    # store image data\n",
    "                    data[\"image\"].append(sized_array.tolist())\n",
    "                    print(\"{}\".format(file_path))\n",
    "                except Exception as e:                                                    \n",
    "                    print('Image failed to process: ' + e)\n",
    "    \n",
    "    # dump stored data into json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "        \n",
    "\n",
    "save_test_data(DATASET_AUDIO_TRAIN, DATASET_IMAGE_TRAIN, JSON_TRAIN, num_segments=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-sword",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
